# .github/workflows/cuenly-deploy.yml
name: Unified CI/CD - Backend & Frontend

on:
  push:
    branches: [ main, master, develop ]
    paths:
      - 'backend/**'
      - 'frontend/**'
      - 'config/**'
      - 'nginx/**'
      - '.github/workflows/cuenly-deploy.yml'
  pull_request:
    branches: [ main, master ]
    paths:
      - 'backend/**'
      - 'frontend/**'
      - 'config/**'
      - 'nginx/**'
  workflow_dispatch:
    inputs:
      deploy_backend:
        description: 'Force deploy backend'
        type: boolean
        default: false
      deploy_frontend:
        description: 'Force deploy frontend'
        type: boolean
        default: false
      environment:
        description: 'Target environment'
        type: choice
        options:
          - development
          - staging
          - production
        default: development

permissions:
  contents: read
  packages: write

env:
  REGISTRY: ghcr.io
  BASE_IMAGE_NAME: ${{ github.repository }}
  DOCKER_BUILDKIT: "1"

concurrency:
  group: deploy-${{ github.ref }}-${{ github.event_name }}
  cancel-in-progress: false

jobs:
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      backend-changed: ${{ steps.changes.outputs.backend }}
      frontend-changed: ${{ steps.changes.outputs.frontend }}
      config-changed: ${{ steps.changes.outputs.config }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Detect changes
        id: changes
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "backend=${{ github.event.inputs.deploy_backend || 'true' }}" >> $GITHUB_OUTPUT
            echo "frontend=${{ github.event.inputs.deploy_frontend || 'true' }}" >> $GITHUB_OUTPUT
            echo "config=true" >> $GITHUB_OUTPUT
          else
            # Detectar cambios desde el Ãºltimo commit
            if [ "${{ github.event_name }}" == "pull_request" ]; then
              BASE_SHA="${{ github.event.pull_request.base.sha }}"
            else
              BASE_SHA="${{ github.event.before }}"
            fi
            
            # Si es el primer push o no hay commit anterior, comparar con HEAD~1
            if [ "$BASE_SHA" == "0000000000000000000000000000000000000000" ] || [ -z "$BASE_SHA" ]; then
              BASE_SHA="HEAD~1"
            fi
            
            # Obtener lista de archivos cambiados
            CHANGED_FILES=$(git diff --name-only $BASE_SHA HEAD)
            echo "ğŸ“ Archivos cambiados:"
            echo "$CHANGED_FILES"
            
            # Detectar cambios en backend (cÃ³digo o k8s)
            BACKEND_CHANGED=$(echo "$CHANGED_FILES" | grep -E '^backend/' > /dev/null && echo "true" || echo "false")
            
            # Detectar cambios en frontend (cÃ³digo o k8s)
            FRONTEND_CHANGED=$(echo "$CHANGED_FILES" | grep -E '^frontend/' > /dev/null && echo "true" || echo "false")
            
            # Detectar cambios en config global
            CONFIG_CHANGED=$(echo "$CHANGED_FILES" | grep -E '^config/|^nginx/|^docker-compose.yml|\.github/workflows/' > /dev/null && echo "true" || echo "false")
            
            # Si hay cambios en config o workflow, rebuildeamos todo
            if [ "$CONFIG_CHANGED" == "true" ]; then
              echo "ğŸ”§ Cambios globales detectados, rebuildeando ambos componentes"
              BACKEND_CHANGED="true"
              FRONTEND_CHANGED="true"
            fi
            
            echo "backend=$BACKEND_CHANGED" >> $GITHUB_OUTPUT
            echo "frontend=$FRONTEND_CHANGED" >> $GITHUB_OUTPUT
            echo "config=$CONFIG_CHANGED" >> $GITHUB_OUTPUT
          fi
          
          echo "ğŸ” Changes detected:"
          echo "  Backend: $(grep 'backend=' $GITHUB_OUTPUT | cut -d'=' -f2)"
          echo "  Frontend: $(grep 'frontend=' $GITHUB_OUTPUT | cut -d'=' -f2)"
          echo "  Config: $(grep 'config=' $GITHUB_OUTPUT | cut -d'=' -f2)"

  build-backend:
    needs: detect-changes
    if: needs.detect-changes.outputs.backend-changed == 'true' || needs.detect-changes.outputs.config-changed == 'true'
    runs-on: self-hosted
    outputs:
      image-digest: ${{ steps.build.outputs.digest }}
      image-tag: ${{ steps.meta.outputs.tags }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_PAT }}
          
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.BASE_IMAGE_NAME }}-backend
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,format=short
            type=raw,value=latest,enable={{is_default_branch}}
          labels: |
            org.opencontainers.image.source=${{ github.repository }}
            org.opencontainers.image.description=CuenlyApp Backend API
            
      - name: Build and push backend image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=backend
          cache-to: type=gha,mode=max,scope=backend
          platforms: linux/amd64

  build-frontend:
    needs: detect-changes
    if: needs.detect-changes.outputs.frontend-changed == 'true' || needs.detect-changes.outputs.config-changed == 'true'
    runs-on: self-hosted
    outputs:
      image-digest: ${{ steps.build.outputs.digest }}
      image-tag: ${{ steps.meta.outputs.tags }}
    steps:

      - uses: actions/checkout@v4
      
      # âœ… NUEVO: Generar environments con secretos
      - name: Generate environment files with secrets
        run: |
          mkdir -p frontend/src/environments
          
          # Generar environment.ts
          cat > frontend/src/environments/environment.ts << 'EOF'
          export const environment = {
            production: false,
            apiUrl: '',
            firebase: {
              apiKey: "${{ secrets.FIREBASE_API_KEY }}",
              authDomain: "${{ secrets.FIREBASE_AUTH_DOMAIN }}",
              projectId: "${{ secrets.FIREBASE_PROJECT_ID }}",
              storageBucket: "${{ secrets.FIREBASE_STORAGE_BUCKET }}",
              messagingSenderId: "${{ secrets.FIREBASE_MESSAGING_SENDER_ID }}",
              appId: "${{ secrets.FIREBASE_APP_ID }}",
              measurementId: "${{ secrets.FIREBASE_MEASUREMENT_ID }}"
            }
          };
          EOF
          
          # Generar environment.prod.ts
          cat > frontend/src/environments/environment.prod.ts << 'EOF'
          export const environment = {
            production: true,
            apiUrl: '',
            firebase: {
              apiKey: "${{ secrets.FIREBASE_API_KEY }}",
              authDomain: "${{ secrets.FIREBASE_AUTH_DOMAIN }}",
              projectId: "${{ secrets.FIREBASE_PROJECT_ID }}",
              storageBucket: "${{ secrets.FIREBASE_STORAGE_BUCKET }}",
              messagingSenderId: "${{ secrets.FIREBASE_MESSAGING_SENDER_ID }}",
              appId: "${{ secrets.FIREBASE_APP_ID }}",
              measurementId: "${{ secrets.FIREBASE_MEASUREMENT_ID }}"
            }
          };
          EOF
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_PAT }}
          
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.BASE_IMAGE_NAME }}-frontend
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,format=short
            type=raw,value=latest,enable={{is_default_branch}}
          labels: |
            org.opencontainers.image.source=${{ github.repository }}
            org.opencontainers.image.description=CuenlyApp Frontend Application
            
      - name: Build and push frontend image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          file: ./frontend/Dockerfile.proxy
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=frontend
          cache-to: type=gha,mode=max,scope=frontend
          platforms: linux/amd64

  deploy-backend:
    needs: [detect-changes, build-backend]
    # Backend se despliega si cambiÃ³ backend O config Y el build fue exitoso Y estamos en rama principal
    if: always() && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master') && (needs.detect-changes.outputs.backend-changed == 'true' || needs.detect-changes.outputs.config-changed == 'true') && (needs.build-backend.result == 'success' || needs.build-backend.result == 'skipped')
    runs-on: self-hosted
    environment: ${{ github.event.inputs.environment || 'development' }}
    env:
      NAMESPACE: cuenly-backend
    outputs:
      backend-ready: ${{ steps.health-check.outputs.ready }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup kubectl context
        run: |
          kubectl config current-context
          
      - name: Ensure namespace exists
        run: |
          kubectl get ns ${{ env.NAMESPACE }} || kubectl create ns ${{ env.NAMESPACE }}
          
      - name: Create/Update image pull secret
        run: |
          kubectl create secret docker-registry ghcr-secret \
            --docker-server=${{ env.REGISTRY }} \
            --docker-username=${{ github.actor }} \
            --docker-password=${{ secrets.GHCR_PAT }} \
            --namespace=${{ env.NAMESPACE }} \
            --dry-run=client -o yaml | kubectl apply -f -
            
      - name: Create/Update backend secrets
        run: |
          set -euo pipefail
          kubectl delete secret backend-env-secrets -n ${{ env.NAMESPACE }} --ignore-not-found=true
          kubectl create secret generic backend-env-secrets \
            --namespace=${{ env.NAMESPACE }} \
            --from-literal=MONGODB_URL="${{ secrets.MONGODB_URL }}" \
            --from-literal=MONGODB_DATABASE="${{ secrets.MONGODB_DATABASE }}" \
            --from-literal=MONGODB_COLLECTION="${{ secrets.MONGODB_COLLECTION }}" \
            --from-literal=OPENAI_API_KEY="${{ secrets.OPENAI_API_KEY }}" \
            --from-literal=API_HOST="${{ secrets.API_HOST }}" \
            --from-literal=API_PORT="${{ secrets.API_PORT }}" \
            --from-literal=LOG_LEVEL="${{ secrets.LOG_LEVEL }}" \
            --from-literal=TEMP_PDF_DIR="${{ secrets.TEMP_PDF_DIR }}" \
            --from-literal=JOB_INTERVAL_MINUTES="${{ secrets.JOB_INTERVAL_MINUTES }}" \
            --from-literal=AUTH_REQUIRE="${{ secrets.AUTH_REQUIRE }}" \
            --from-literal=FIREBASE_PROJECT_ID="${{ secrets.FIREBASE_PROJECT_ID }}" \
            --from-literal=MULTI_TENANT_ENFORCE="${{ secrets.MULTI_TENANT_ENFORCE }}"
            
      - name: Create/Update MongoDB secrets
        run: |
          set -euo pipefail
          kubectl delete secret cuenly-backend-secrets -n ${{ env.NAMESPACE }} --ignore-not-found=true
          kubectl create secret generic cuenly-backend-secrets \
            --namespace=${{ env.NAMESPACE }} \
            --from-literal=mongodb-root-username="${{ secrets.MONGODB_ROOT_USERNAME }}" \
            --from-literal=mongodb-root-password="${{ secrets.MONGODB_ROOT_PASSWORD }}" \
            --from-literal=mongodb-database="${{ secrets.MONGODB_DATABASE }}"
          echo "âœ… Secrets de MongoDB creados correctamente"
            
      - name: Cleanup old MongoDB resources
        run: |
          # Eliminar recursos problemÃ¡ticos del replica set
          kubectl delete statefulset mongodb -n ${{ env.NAMESPACE }} --ignore-not-found=true
          kubectl delete service mongodb -n ${{ env.NAMESPACE }} --ignore-not-found=true
          kubectl delete secret mongodb-keyfile -n ${{ env.NAMESPACE }} --ignore-not-found=true
          kubectl delete job mongodb-appuser -n ${{ env.NAMESPACE }} --ignore-not-found=true
          kubectl delete pdb mongodb-pdb -n ${{ env.NAMESPACE }} --ignore-not-found=true
          
          # Esperar a que se limpien los pods
          sleep 10
            
      - name: Deploy simple MongoDB
        run: |
          set -euo pipefail
          kubectl apply -f backend/k8s/mongodb-simple.yaml -n ${{ env.NAMESPACE }}
          kubectl rollout status deployment/mongodb -n ${{ env.NAMESPACE }} --timeout=300s
          kubectl wait --for=condition=ready pod -l app=mongodb -n ${{ env.NAMESPACE }} --timeout=300s
          
      - name: Apply NetworkPolicies
        run: |
          kubectl apply -f backend/k8s/networkpolicy-mongodb.yaml -n ${{ env.NAMESPACE }}
          kubectl apply -f backend/k8s/networkpolicy-backend.yaml -n ${{ env.NAMESPACE }}
          
      - name: Initialize MongoDB with script
        run: |
          set -euo pipefail
          echo "ğŸ”§ Inicializando MongoDB con datos base..."
          # Esperar que MongoDB estÃ© completamente listo
          sleep 15
          
          # Verificar conectividad a MongoDB
          kubectl exec deployment/mongodb -n ${{ env.NAMESPACE }} -- mongosh --eval 'db.adminCommand({ ping: 1 })'
          
          # Aplicar script de inicializaciÃ³n si existe usando autenticaciÃ³n admin
          if [ -f "config/mongo-init.js" ]; then
            kubectl cp config/mongo-init.js ${{ env.NAMESPACE }}/$(kubectl get pod -l app=mongodb -n ${{ env.NAMESPACE }} -o jsonpath='{.items[0].metadata.name}'):/tmp/mongo-init.js
            
            # Ejecutar con autenticaciÃ³n admin
            ROOT_USER=$(kubectl get secret cuenly-backend-secrets -n ${{ env.NAMESPACE }} -o jsonpath='{.data.mongodb-root-username}' | base64 -d)
            ROOT_PASS=$(kubectl get secret cuenly-backend-secrets -n ${{ env.NAMESPACE }} -o jsonpath='{.data.mongodb-root-password}' | base64 -d)
            
            kubectl exec deployment/mongodb -n ${{ env.NAMESPACE }} -- mongosh -u "$ROOT_USER" -p "$ROOT_PASS" --authenticationDatabase admin cuenlyapp_warehouse /tmp/mongo-init.js
            echo "âœ… Script de inicializaciÃ³n aplicado"
          else
            echo "â„¹ï¸  No se encontrÃ³ config/mongo-init.js"
          fi
          
          # Aplicar Ã­ndices de rendimiento
          if [ -f "config/mongo-indexes.js" ]; then
            echo "ğŸš€ Aplicando Ã­ndices de rendimiento..."
            kubectl cp config/mongo-indexes.js ${{ env.NAMESPACE }}/$(kubectl get pod -l app=mongodb -n ${{ env.NAMESPACE }} -o jsonpath='{.items[0].metadata.name}'):/tmp/mongo-indexes.js
            kubectl exec deployment/mongodb -n ${{ env.NAMESPACE }} -- mongosh -u "$ROOT_USER" -p "$ROOT_PASS" --authenticationDatabase admin /tmp/mongo-indexes.js || true
            echo "âœ… Ãndices de rendimiento aplicados"
          else
            echo "âš ï¸  No se encontrÃ³ script mongo-indexes.js, continuando..."
          fi
          
      - name: Clean problematic backend resources
        run: |
          set -euo pipefail
          echo "ğŸ§¹ Limpiando recursos problemÃ¡ticos del backend..."
          
          # Eliminar deployment problemÃ¡tico si existe
          kubectl delete deployment cuenly-backend -n ${{ env.NAMESPACE }} --ignore-not-found=true --force --grace-period=0 || true
          
          # Esperar a que los pods terminen
          echo "â³ Esperando terminaciÃ³n de pods..."
          sleep 10
          
          # Forzar eliminaciÃ³n de pods colgados
          kubectl delete pods -l app=cuenly-backend -n ${{ env.NAMESPACE }} --force --grace-period=0 --ignore-not-found=true || true
          
          # Eliminar replica sets huÃ©rfanos
          kubectl delete replicaset -l app=cuenly-backend -n ${{ env.NAMESPACE }} --force --grace-period=0 --ignore-not-found=true || true
          
          echo "âœ… Limpieza completada"
          
      - name: Deploy backend application  
        run: |
          set -euo pipefail
          echo "ğŸš€ Desplegando backend..."
          
          # Aplicar configuraciÃ³n de Kubernetes
          kubectl apply -f backend/k8s/deployment.yaml -n ${{ env.NAMESPACE }}
          
          # Obtener SHA corto para tag Ãºnico
          SHORT_SHA=$(echo $GITHUB_SHA | cut -c1-7)
          echo "ğŸ“¦ Desplegando imagen: ${{ env.REGISTRY }}/${{ env.BASE_IMAGE_NAME }}-backend:sha-${SHORT_SHA}"
          
          # Actualizar imagen del deployment
          kubectl set image deployment/cuenly-backend \
            cuenly-backend=${{ env.REGISTRY }}/${{ env.BASE_IMAGE_NAME }}-backend:sha-${SHORT_SHA} \
            -n ${{ env.NAMESPACE }}
          
          # Forzar actualizaciÃ³n con anotaciones Ãºnicas para garantizar pull de imagen
          kubectl patch deployment cuenly-backend -n ${{ env.NAMESPACE }} -p \
            "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"kubectl.kubernetes.io/restartedAt\":\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\"forceUpdate\":\"$(date +%s)\",\"gitSha\":\"${SHORT_SHA}\"}}}}}"
          
          # Esperar que el rollout complete
          kubectl rollout status deployment/cuenly-backend -n ${{ env.NAMESPACE }} --timeout=300s
          
          # Verificar que los pods estÃ©n usando la imagen correcta
          echo "ğŸ” Verificando imagen desplegada:"
          CURRENT_IMAGES=$(kubectl get pods -n ${{ env.NAMESPACE }} -l app=cuenly-backend -o jsonpath='{.items[*].spec.containers[*].image}')
          echo "ImÃ¡genes en pods: $CURRENT_IMAGES"
          
          if echo "$CURRENT_IMAGES" | grep -q "sha-${SHORT_SHA}"; then
            echo "âœ… Backend desplegado correctamente con SHA: ${SHORT_SHA}"
          else
            echo "âŒ Error: Backend no estÃ¡ usando la imagen esperada"
            exit 1
          fi
          
      - name: Remove old backend ingress (now handled by frontend)
        run: |
          kubectl delete ingress cuenly-backend-ingress -n ${{ env.NAMESPACE }} --ignore-not-found=true
          echo "âœ… Backend ingress eliminado - ahora se maneja desde frontend ingress"
          
      - name: Backend health check
        id: health-check
        run: |
          set -euo pipefail
          echo "â³ Esperando servicio backend..."
          sleep 30
          
          # Verificar que el servicio existe
          kubectl get svc cuenly-backend-service -n ${{ env.NAMESPACE }}
          BACKEND_IP=$(kubectl get svc cuenly-backend-service -n ${{ env.NAMESPACE }} -o jsonpath='{.spec.clusterIP}')
          echo "ğŸ” Backend service IP: $BACKEND_IP"
          
          # Health check con reintentos
          for i in $(seq 1 15); do
            if curl -fsS "http://${BACKEND_IP}:8000/health" > /dev/null; then
              echo "âœ… Backend healthy and ready"
              echo "ready=true" >> $GITHUB_OUTPUT
              exit 0
            fi
            echo "Attempt $i/15 failed; retrying in 10s..."
            sleep 10
          done
          
          echo "âŒ Backend health check failed after 15 attempts"
          kubectl logs deployment/cuenly-backend -n ${{ env.NAMESPACE }} --tail=50
          exit 1

  debug-conditions:
    needs: [detect-changes, build-frontend, deploy-backend]
    if: always()
    runs-on: self-hosted
    steps:
      - name: Debug all conditions
        run: |
          echo "ğŸ” DEBUGGING DEPLOY CONDITIONS"
          echo "=============================="
          echo "ğŸŒ¿ Branch info:"
          echo "  github.ref: ${{ github.ref }}"
          echo "  Is main/master: ${{ github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' }}"
          echo ""
          echo "ğŸ“¦ Build results:"
          echo "  build-frontend.result: ${{ needs.build-frontend.result }}"
          echo "  deploy-backend.result: ${{ needs.deploy-backend.result }}"
          echo "  backend-ready: '${{ needs.deploy-backend.outputs.backend-ready }}'"
          echo ""
          echo "ğŸ”„ Changes detected:"
          echo "  frontend-changed: '${{ needs.detect-changes.outputs.frontend-changed }}'"
          echo "  config-changed: '${{ needs.detect-changes.outputs.config-changed }}'"
          echo ""
          echo "ğŸ¯ SHOULD DEPLOY:"
          echo "  Backend: ${{ (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master') && (needs.detect-changes.outputs.backend-changed == 'true' || needs.detect-changes.outputs.config-changed == 'true') && (needs.build-backend.result == 'success' || needs.build-backend.result == 'skipped') }}"
          echo "  Frontend: ${{ (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master') && (needs.build-frontend.result == 'success' || needs.build-frontend.result == 'skipped') && ((needs.detect-changes.outputs.frontend-changed == 'true' || needs.detect-changes.outputs.config-changed == 'true') || (needs.deploy-backend.result == 'success' && needs.deploy-backend.outputs.backend-ready == 'true')) }}"

  deploy-frontend:
    needs: [detect-changes, build-frontend, deploy-backend]
    # Frontend se despliega si cambiÃ³ O si backend cambiÃ³ (para mantener sincronizaciÃ³n) Y estamos en rama principal
    if: always() && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master') && (needs.build-frontend.result == 'success' || needs.build-frontend.result == 'skipped') && ((needs.detect-changes.outputs.frontend-changed == 'true' || needs.detect-changes.outputs.config-changed == 'true') || (needs.deploy-backend.result == 'success' && needs.deploy-backend.outputs.backend-ready == 'true'))
    runs-on: self-hosted
    environment: ${{ github.event.inputs.environment || 'development' }}
    env:
      NAMESPACE: cuenly-frontend
    steps:
      - uses: actions/checkout@v4
      
      - name: Log in to GHCR
        run: |
          echo "${{ secrets.GHCR_PAT }}" | docker login ${{ env.REGISTRY }} -u ${{ github.actor }} --password-stdin
      
      - name: Ensure namespace exists
        run: |
          kubectl apply -f frontend/k8s/namespace.yaml
          
      - name: Create/Update image pull secret
        run: |
          kubectl create secret docker-registry ghcr-secret \
            --docker-server=${{ env.REGISTRY }} \
            --docker-username=${{ github.actor }} \
            --docker-password=${{ secrets.GHCR_PAT }} \
            --namespace=${{ env.NAMESPACE }} \
            --dry-run=client -o yaml | kubectl apply -f -
            
      - name: Deploy frontend infrastructure
        run: |
          # Aplicar backend proxy service primero
          kubectl apply -f frontend/k8s/backend-proxy-service.yaml -n ${{ env.NAMESPACE }}
          kubectl apply -f frontend/k8s/configmap.yaml -n ${{ env.NAMESPACE }}
          kubectl apply -f frontend/k8s/networkpolicy.yaml -n ${{ env.NAMESPACE }}
          kubectl apply -f frontend/k8s/ingress.yaml -n ${{ env.NAMESPACE }}
          
      - name: Verify backend service availability
        run: |
          echo "ğŸ” Verificando disponibilidad del backend antes del despliegue frontend..."
          # Verificar que el servicio backend existe y responde
          kubectl get svc cuenly-backend-service -n cuenly-backend
          BACKEND_IP=$(kubectl get svc cuenly-backend-service -n cuenly-backend -o jsonpath='{.spec.clusterIP}')
          
          if ! curl -fsS "http://${BACKEND_IP}:8000/health" > /dev/null; then
            echo "âŒ Backend no estÃ¡ respondiendo, esperando..."
            for i in $(seq 1 10); do
              if curl -fsS "http://${BACKEND_IP}:8000/health" > /dev/null; then
                echo "âœ… Backend ahora estÃ¡ disponible"
                break
              fi
              echo "Intento $i/10 fallido, reintentando en 15s..."
              sleep 15
            done
          else
            echo "âœ… Backend estÃ¡ disponible"
          fi
          
      - name: Deploy frontend application
        run: |
          echo "ğŸš€ Desplegando frontend..."
          
          # Aplicar configuraciÃ³n de Kubernetes
          kubectl apply -f frontend/k8s/deployment.yaml -n ${{ env.NAMESPACE }}
          
          # Obtener SHA corto para tag Ãºnico
          SHORT_SHA=$(echo $GITHUB_SHA | cut -c1-7)
          echo "ğŸ“¦ Desplegando imagen: ${{ env.REGISTRY }}/${{ env.BASE_IMAGE_NAME }}-frontend:sha-${SHORT_SHA}"
          
          # Actualizar imagen del deployment
          kubectl set image deployment/cuenly-frontend \
            cuenly-frontend=${{ env.REGISTRY }}/${{ env.BASE_IMAGE_NAME }}-frontend:sha-${SHORT_SHA} \
            -n ${{ env.NAMESPACE }}
          
          # Forzar actualizaciÃ³n con anotaciones Ãºnicas para garantizar pull de imagen
          kubectl patch deployment cuenly-frontend -n ${{ env.NAMESPACE }} -p \
            "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"kubectl.kubernetes.io/restartedAt\":\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\"forceUpdate\":\"$(date +%s)\",\"gitSha\":\"${SHORT_SHA}\"}}}}}"
          
          # Esperar que el rollout complete
          kubectl rollout status deployment/cuenly-frontend -n ${{ env.NAMESPACE }} --timeout=600s
          
          # Verificar que los pods estÃ©n usando la imagen correcta
          echo "ğŸ” Verificando imagen desplegada:"
          CURRENT_IMAGES=$(kubectl get pods -n ${{ env.NAMESPACE }} -l app=cuenly-frontend -o jsonpath='{.items[*].spec.containers[*].image}')
          echo "ImÃ¡genes en pods: $CURRENT_IMAGES"
          
          if echo "$CURRENT_IMAGES" | grep -q "sha-${SHORT_SHA}"; then
            echo "âœ… Frontend desplegado correctamente con SHA: ${SHORT_SHA}"
          else
            echo "âŒ Error: Frontend no estÃ¡ usando la imagen esperada"
            exit 1
          fi
          
      - name: Frontend health check
        run: |
          sleep 15
          # Verificar que el servicio frontend existe
          if kubectl get service cuenly-frontend-service -n ${{ env.NAMESPACE }} > /dev/null 2>&1; then
            FRONTEND_IP=$(kubectl get service cuenly-frontend-service -n ${{ env.NAMESPACE }} -o jsonpath='{.spec.clusterIP}')
            for i in {1..10}; do
              if curl -f http://$FRONTEND_IP/ > /dev/null 2>&1; then
                echo "âœ… Frontend health check passed"
                break
              fi
              echo "Attempt $i failed, retrying in 10 seconds..."
              sleep 10
              if [ $i -eq 10 ]; then
                echo "âŒ Frontend health check failed after 10 attempts"
                kubectl logs deployment/cuenly-frontend -n ${{ env.NAMESPACE }} --tail=50
                exit 1
              fi
            done
          else
            echo "âš ï¸  Frontend service not found, checking nginx availability via pods..."
            kubectl get pods -n ${{ env.NAMESPACE }} -l app=cuenly-frontend
          fi

  deployment-summary:
    needs: [detect-changes, build-backend, build-frontend, deploy-backend, deploy-frontend]
    if: always()
    runs-on: self-hosted
    steps:
      - name: Summary
        run: |
          echo "ğŸ¯ Deployment Summary"
          echo "=================="
          echo "ğŸŒ¿ Branch: ${{ github.ref_name }}"
          echo "ğŸ“¦ Changes:"
          echo "  Backend changed: ${{ needs.detect-changes.outputs.backend-changed }}"
          echo "  Frontend changed: ${{ needs.detect-changes.outputs.frontend-changed }}"
          echo "  Config changed: ${{ needs.detect-changes.outputs.config-changed }}"
          echo ""
          echo "ğŸ—ï¸  Build results:"
          echo "  Backend build: ${{ needs.build-backend.result || 'skipped' }}"
          echo "  Frontend build: ${{ needs.build-frontend.result || 'skipped' }}"
          echo ""
          echo "ğŸš€ Deploy results:"
          echo "  Backend deployment: ${{ needs.deploy-backend.result || 'skipped' }}"
          echo "  Frontend deployment: ${{ needs.deploy-frontend.result || 'skipped' }}"
          echo "  Backend ready: ${{ needs.deploy-backend.outputs.backend-ready || 'false' }}"
          echo ""
          if [ "${{ github.ref }}" == "refs/heads/main" ] || [ "${{ github.ref }}" == "refs/heads/master" ]; then
            echo "ğŸ“‹ Cluster Status:"
            kubectl get pods -n cuenly-backend -o wide || echo "No backend pods"
            kubectl get pods -n cuenly-frontend -o wide || echo "No frontend pods"
            echo ""
            echo "ğŸŒ Services:"
            kubectl get svc -n cuenly-backend || echo "No backend services"
            kubectl get svc -n cuenly-frontend || echo "No frontend services"
          else
            echo "â„¹ï¸  Deploy skipped - not on main/master branch"
          fi