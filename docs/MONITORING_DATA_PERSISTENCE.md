# Persistencia de Datos en Monitoring Stack - ConfiguraciÃ³n Actualizada

## ðŸ“Š Estado Actual (ConfiguraciÃ³n Persistente - 30 dÃ­as)

### âœ… TODOS los componentes con persistencia

- **Grafana**: PersistentVolumeClaim de 10GB
  - Dashboards, usuarios, configuraciÃ³n de datasources
  - Storage Class: Longhorn
  - Persiste indefinidamente
  
- **Loki**: PersistentVolumeClaim de 5GB
  - **RetenciÃ³n de logs: 30 dÃ­as** âœ…
  - Logs histÃ³ricos se mantienen despuÃ©s de reinicios
  - Storage Class: Longhorn
  - Auto-limpieza de logs > 30 dÃ­as
  - Suficiente para ~50GB de logs/dÃ­a
  
- **Prometheus**: PersistentVolumeClaim de 8GB
  - **RetenciÃ³n de mÃ©tricas: 30 dÃ­as** âœ…
  - MÃ©tricas histÃ³ricas se mantienen despuÃ©s de reinicios
  - Storage Class: Longhorn
  - Auto-limpieza de mÃ©tricas > 30 dÃ­as
  - Suficiente para proyectos pequeÃ±os/medianos
  
- **ConfigMaps**: Almacenados en etcd de Kubernetes
  - ConfiguraciÃ³n de Promtail (todos los namespaces)
  - ConfiguraciÃ³n de Prometheus (scraping y alertas)
  - ConfiguraciÃ³n de AlertManager (SMTP)
  - Persisten indefinidamente

---

## ðŸ”„ Comportamiento al Reiniciar el Servidor

```bash
# 1. Reinicias el nodo de Kubernetes
sudo reboot

# 2. Kubernetes se levanta (systemd service)
systemctl status kubelet

# 3. Los pods se recrean automÃ¡ticamente
kubectl get pods -n cuenly-monitoring

# RESULTADO: TODO funciona con datos histÃ³ricos âœ…
# â†’ Grafana: Mantiene dashboards y configuraciÃ³n
# â†’ Loki: Mantiene logs de los Ãºltimos 30 dÃ­as
# â†’ Prometheus: Mantiene mÃ©tricas de los Ãºltimos 30 dÃ­as
# â†’ Promtail: Recolecta logs de todos los namespaces
```

---

## ðŸ›¡ï¸ GarantÃ­as de ConfiguraciÃ³n con GitHub Actions

### âœ… Manifiestos aplicados automÃ¡ticamente

Tu workflow `.github/workflows/cuenly-deploy.yml` aplica los manifiestos al cluster:

```yaml
# GitHub Actions ejecuta:
kubectl apply -f k8s-monitoring/simple-monitoring-stack.yaml

# Esto crea en Kubernetes (etcd):
- Namespace: cuenly-monitoring
- PersistentVolumeClaims (3): grafana, loki, prometheus
- Deployments (3): grafana, loki, prometheus
- DaemonSet: promtail
- ConfigMaps (4): grafana, loki, prometheus, promtail
- Services (3): grafana, loki, prometheus
```

**Una vez aplicados con `kubectl apply`, los manifiestos viven en Kubernetes indefinidamente**, incluso si:
- GitHub deja de funcionar âŒ
- Borras el repositorio âŒ
- El workflow falla âŒ
- Reinicias el servidor âœ…

---

## ðŸ“¦ Almacenamiento Actual

| Componente | Storage | Capacidad | RetenciÃ³n | Persiste Config | Persiste Datos |
|------------|---------|-----------|-----------|-----------------|----------------|
| Grafana | PVC (Longhorn) | 10GB | Indefinido | âœ… SÃ | âœ… SÃ |
| Loki | PVC (Longhorn) | 5GB | 30 dÃ­as | âœ… SÃ | âœ… SÃ |
| Prometheus | PVC (Longhorn) | 8GB | 30 dÃ­as | âœ… SÃ | âœ… SÃ |
| Promtail | ConfigMap | N/A | N/A | âœ… SÃ | N/A |
| AlertManager | ConfigMap | N/A | N/A | âœ… SÃ | N/A |

**Total de almacenamiento: ~23GB** (deja 77GB libres para otros proyectos)

---

## ðŸš€ Cambios Aplicados

### Antes (VolÃ¡til):
```yaml
# Loki y Prometheus perdÃ­an datos al reiniciar
volumes:
  - name: storage
    emptyDir: {}  # âŒ EfÃ­mero

# RetenciÃ³n corta
args:
  - --storage.tsdb.retention.time=7d  # Solo 7 dÃ­as
```

### Ahora (Persistente):
```yaml
# PersistentVolumeClaims creados
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: cuenly-loki-storage
spec:
  storageClassName: longhorn
  resources:
    requests:
      storage: 5Gi  # âœ… Optimizado para uso real (~100MB/dÃ­a)

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: cuenly-prometheus-storage
spec:
  storageClassName: longhorn
  resources:
    requests:
      storage: 8Gi  # âœ… Optimizado para uso real (~200MB/dÃ­a)

# Deployments usan PVCs
volumes:
  - name: storage
    persistentVolumeClaim:
      claimName: cuenly-loki-storage  # âœ… Persistente

# RetenciÃ³n extendida
# Prometheus:
args:
  - --storage.tsdb.retention.time=30d  # âœ… 30 dÃ­as

# Loki:
limits_config:
  reject_old_samples_max_age: 720h  # 30 dÃ­as
chunk_store_config:
  max_look_back_period: 720h  # 30 dÃ­as
table_manager:
  retention_deletes_enabled: true
  retention_period: 720h  # 30 dÃ­as
```

---

## ðŸ“‹ Resumen de Cambios

### Archivos Modificados:
1. **k8s-monitoring/simple-monitoring-stack.yaml**
   - âœ… Agregados 2 PersistentVolumeClaims (Loki 5GB, Prometheus 8GB)
   - âœ… Cambiados `emptyDir` â†’ `persistentVolumeClaim` en Deployments
   - âœ… RetenciÃ³n Prometheus: 7d â†’ 30d
   - âœ… RetenciÃ³n Loki: 7d â†’ 30d
   - âœ… TamaÃ±os optimizados para uso real (~13GB total vs 150GB inicial)

### Beneficios:
- âœ… **Datos histÃ³ricos sobreviven reinicios** (30 dÃ­as de logs y mÃ©tricas)
- âœ… **ConfiguraciÃ³n 100% persistente**
- âœ… **Auto-limpieza automÃ¡tica** (logs/mÃ©tricas > 30 dÃ­as se eliminan)
- âœ… **Deploy automÃ¡tico via GitHub Actions**

---

## ðŸ” VerificaciÃ³n Post-Deploy

```bash
# 1. Verificar PVCs creados
kubectl get pvc -n cuenly-monitoring
# Esperado:
# cuenly-grafana-storage       Bound    10Gi
# cuenly-loki-storage          Bound    5Gi
# cuenly-prometheus-storage    Bound    8Gi

# 2. Verificar pods usando PVCs
kubectl get pods -n cuenly-monitoring -o wide

# 3. Verificar retenciÃ³n de Prometheus (30 dÃ­as)
kubectl logs -n cuenly-monitoring deployment/cuenly-prometheus | grep retention
# â†’ storage.tsdb.retention.time=30d

# 4. Verificar configuraciÃ³n de Loki (30 dÃ­as)
kubectl exec -n cuenly-monitoring deployment/cuenly-loki -- cat /etc/loki/loki.yaml | grep retention_period
# â†’ retention_period: 720h

# 5. Reiniciar y verificar que datos persisten
kubectl delete pod -n cuenly-monitoring -l app=cuenly-loki
kubectl delete pod -n cuenly-monitoring -l app=cuenly-prometheus
# â†’ Espera 30s y verifica que los datos histÃ³ricos siguen disponibles en Grafana
```

---

## ðŸŽ¯ Aplicar Cambios

```bash
# 1. Commit y push
git add k8s-monitoring/simple-monitoring-stack.yaml docs/MONITORING_DATA_PERSISTENCE.md
git commit -m "feat: Add 30-day persistent storage for Loki and Prometheus"
git push origin main

# 2. GitHub Actions aplica automÃ¡ticamente los cambios
# â†’ Crea los PVCs
# â†’ Reinicia Loki y Prometheus con nuevos volÃºmenes
# â†’ Los datos empiezan a acumularse en almacenamiento persistente

# 3. Verificar en el cluster
kubectl get pvc -n cuenly-monitoring
kubectl get pods -n cuenly-monitoring
```

---

## ðŸ“š Notas Importantes

1. **Los PVCs se crean una sola vez**: Al aplicar el manifiesto por primera vez, Longhorn provisiona los volÃºmenes. En deploys posteriores, los pods se conectan a los PVCs existentes.

2. **MigraciÃ³n de datos**: Como Loki y Prometheus usaban `emptyDir`, NO hay datos histÃ³ricos previos. Los datos nuevos se almacenarÃ¡n en los PVCs desde el momento del deploy.

3. **Espacio en disco**: Verifica que tu cluster Longhorn tenga al menos 25GB libres:
   - Grafana: 10GB
   - Loki: 5GB
   - Prometheus: 8GB
   - **Total: ~23GB para monitoring (deja ~77GB para otros proyectos)**

4. **Auto-limpieza**: Loki y Prometheus eliminarÃ¡n automÃ¡ticamente datos > 30 dÃ­as, no necesitas hacer nada manualmente.

5. **Backups**: Los PVCs de Longhorn pueden respaldarse usando Longhorn UI o sus snapshots automÃ¡ticos (si lo tienes configurado).

---

## ðŸ”— Referencias

- **Workflow**: `.github/workflows/cuenly-deploy.yml`
- **Manifiestos**: `k8s-monitoring/simple-monitoring-stack.yaml`
- **Secrets**: GitHub Settings â†’ Secrets â†’ Actions
- **DocumentaciÃ³n relacionada**: 
  - `docs/MONITORING_SCOPE_CONFIG.md` (Monitoreo de todos los namespaces)
  - `docs/PROMETHEUS_ALERTMANAGER_CONFIG.md` (AlertManager SMTP)
