# Plan de Optimizaci√≥n ‚Äî CuenlyApp

> Generado: 2026-02-27
> Basado en: auditor√≠a completa de docs/, backend/ y frontend/
> Ver tambi√©n: `CLAUDE.md` en la ra√≠z del proyecto para contexto t√©cnico completo.

---

## Resumen Ejecutivo

CuenlyApp tiene una arquitectura s√≥lida y un flujo de procesamiento bien pensado. Sin embargo, hay problemas concretos que degradan la experiencia del usuario y representan riesgos de seguridad y escalabilidad. Este plan los organiza por impacto real, no por complejidad t√©cnica.

**Criterios de prioridad:**
- üî¥ **CR√çTICO**: Seguridad comprometida o funcionalidad rota para el usuario
- üü† **ALTO**: Experiencia de usuario significativamente afectada o riesgo operacional
- üü° **MEDIO**: Mejora importante pero no urgente
- üü¢ **BAJO**: Refinamiento y deuda t√©cnica

---

## FASE 1 ‚Äî Correcciones Cr√≠ticas (Hacer YA)

### ‚úÖ 1.1 Cola de procesos: eliminar el parpadeo

**Problema:** `queue-events.component.ts` usa `interval(5000)` que hace polling cada 5 segundos y re-renderiza toda la tabla. El usuario no puede leer los datos sin que la pantalla pesta√±ee.

**Soluci√≥n inmediata (sin WebSockets):**
1. Eliminar el auto-refresh autom√°tico.
2. Agregar bot√≥n "Actualizar" prominente (ya existe pero no es el control principal).
3. Mostrar indicador de "√∫ltima actualizaci√≥n hace X segundos".
4. Usar `trackBy: trackByJobId` en el `*ngFor` de la tabla para que Angular no destruya y reconstruya filas existentes.

```typescript
// queue-events.component.ts
// ELIMINAR esto:
private startAutoRefresh(): void {
  this.autoRefreshSub = interval(this.autoRefreshMs).subscribe(() => { ... });
}

// AGREGAR en el template:
// <button (click)="loadEvents()">Actualizar</button>
// <small>√öltima actualizaci√≥n: {{ lastRefresh | date:'HH:mm:ss' }}</small>

// En el *ngFor:
trackByJobId(index: number, item: QueueEvent): string {
  return item.job_id || String(index);
}
```

**Soluci√≥n definitiva (siguiente sprint):** Implementar Server-Sent Events (SSE) en el backend para que el servidor notifique cambios en tiempo real sin polling.

---

### ‚úÖ 1.2 Email admin hardcodeado

**Problema:** `backend/app/repositories/user_repository.py` l√≠nea ~42 tiene `email == 'andyvercha@gmail.com'` hardcodeado.

**Soluci√≥n:**
```python
# settings.py ‚Äî agregar:
ADMIN_EMAILS: List[str] = json.loads(os.getenv("ADMIN_EMAILS", '["andyvercha@gmail.com"]'))

# user_repository.py ‚Äî reemplazar hardcode por:
from app.config.settings import get_settings
settings = get_settings()
is_admin = email in settings.ADMIN_EMAILS
```

**Riesgo si no se hace:** Requiere un deploy para cambiar el admin. Si la cuenta se compromete, no hay forma de revocar sin c√≥digo.

---

### 1.3 üî¥ Contrase√±as IMAP en plaintext

**Problema:** Las contrase√±as de cuentas IMAP se guardan en MongoDB sin cifrar. `EMAIL_CONFIG_ENCRYPTION_KEY` existe en settings pero no est√° completamente implementado en todos los paths de guardado y lectura.

**Soluci√≥n:**
1. Verificar que `config_store.py` usa Fernet para cifrar ANTES de guardar y descifrar DESPU√âS de leer.
2. Verificar que todos los paths que guardan `email_configs` pasan por el mismo encriptador.
3. Migrar registros existentes (script de migraci√≥n one-shot).
4. Documentar que `EMAIL_CONFIG_ENCRYPTION_KEY` es OBLIGATORIO en producci√≥n.

```python
# Patr√≥n a verificar en config_store.py:
from cryptography.fernet import Fernet

def encrypt_password(password: str, key: str) -> str:
    if not key:
        return password  # Sin clave = sin cifrado (solo dev)
    f = Fernet(key.encode())
    return f.encrypt(password.encode()).decode()

def decrypt_password(encrypted: str, key: str) -> str:
    if not key:
        return encrypted
    f = Fernet(key.encode())
    return f.decrypt(encrypted.encode()).decode()
```

---

### 1.4 üî¥ Tokens OAuth sin cifrar

**Problema:** Los access_token y refresh_token de OAuth2 (Gmail) se guardan en plaintext en MongoDB junto a las email_configs.

**Soluci√≥n:** Aplicar el mismo Fernet de `EMAIL_CONFIG_ENCRYPTION_KEY` a los tokens OAuth antes de persistirlos.

---

### ‚úÖ 1.5 print() en c√≥digo de producci√≥n

**Problema:** `task_queue.py` tiene m√∫ltiples `print()` en c√≥digo de threading cr√≠tico.

**Soluci√≥n:** Reemplazar todos los `print()` por `logger = logging.getLogger(__name__)` y las llamadas apropiadas (`logger.debug()`, `logger.info()`, `logger.warning()`).

---

## FASE 2 ‚Äî Problemas de Usuario de Alto Impacto

### 2.1 üü† Panel de Admin: datos reales + redise√±o

**Problemas:**
- Algunas m√©tricas del tab "Stats" no muestran datos reales del sistema
- Dise√±o inconsistente con el resto de la app
- Falta visibilidad de: consumo de IA por usuario, estado de colas en tiempo real, revenue mensual real

**Plan de acci√≥n:**

**A. Conectar m√©tricas reales:**
- `GET /admin/metrics` debe retornar: usuarios activos √∫ltimos 30 d√≠as, facturas procesadas hoy/semana/mes, distribuci√≥n XML vs IA, top 10 usuarios por consumo IA, revenue por plan
- Verificar que los contadores de MongoDB se calculan correctamente

**B. Redise√±ar el dashboard de admin:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Panel Admin                            [Actualizar] ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Usuarios ‚îÇFacturas  ‚îÇ Revenue  ‚îÇ   Colas RQ          ‚îÇ
‚îÇ activos  ‚îÇ hoy      ‚îÇ este mes ‚îÇ   (pendientes/proc) ‚îÇ
‚îÇ   142    ‚îÇ  1,847   ‚îÇ 2.1M PYG ‚îÇ   23 / 4            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  [Usuarios] [IA Limits] [Suscripciones] [Scheduler] ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**C. Agregar:**
- Gr√°fico de facturas por d√≠a (√∫ltimos 30 d√≠as) ‚Äî usar Chart.js ya instalado
- Tabla de consumo IA por usuario (ordenado por mayor consumo)
- Estado en tiempo real de las colas RQ (jobs pendientes, en proceso, fallidos)
- Acceso r√°pido a reset de l√≠mites sin navegar a tab separado

---

### 2.2 üü† Estad√≠sticas: agregar calidad y origen del procesamiento

**Problema:** `/facturas/estadisticas` no muestra de d√≥nde vienen los datos (XML nativo vs OpenAI Vision) ni la calidad del procesamiento.

**Datos que ya existen en MongoDB:**
- `invoice_headers.processing_method` (si existe): `"xml_native"` | `"openai_vision"`
- `processed_emails.status`: `"completed"` | `"failed"` | `"skipped_ai_limit"` | `"error"`

**Endpoint nuevo o extender el existente:**
```python
# GET /invoices/month/{yearMonth}/stats ‚Äî agregar campos:
{
  "by_processing_method": {
    "xml_native": 234,
    "openai_vision": 89,
    "unknown": 5
  },
  "by_status": {
    "completed": 318,
    "failed": 8,
    "skipped_ai_limit": 2
  },
  "quality_score": 97.5  # % de facturas sin error
}
```

**Frontend:** Agregar secci√≥n "Origen y Calidad" en InvoicesStatsComponent con:
- Gr√°fico de dona: XML nativo vs IA vs Desconocido
- Tasa de √©xito del procesamiento
- Facturas pendientes de reprocesar

---

### 2.3 üü† Verificar y completar flujo completo de Pagopar

**Problema declarado por el usuario:** "no s√© qu√© tanto le llegue a faltar"

**Puntos a verificar exhaustivamente:**
1. Flujo completo: registro ‚Üí tarjeta ‚Üí confirmaci√≥n ‚Üí cobro recurrente
2. Estado `PAST_DUE`: ¬øse notifica al usuario? ¬øse bloquea acceso?
3. Reintentos en d√≠as 1, 3, 7: ¬øest√°n implementados como cronjob RQ?
4. Cancelaci√≥n: ¬øelimina la tarjeta en Pagopar o solo en DB?
5. `PagoparResultComponent` (`/pagopar/resultado/:hash`): ¬ømaneja todos los estados?
6. ¬øQu√© pasa si el job de cobro recurrente falla silenciosamente?

**Acci√≥n:** Crear un test end-to-end con las tarjetas sandbox de Pagopar documentadas en `docs/pagopar-integration.md`.

**Sandbox:**
- Visa (uPay): `4111 1111 1111 1111`
- Mastercard: `5100 0000 0000 0000`

---

### 2.4 üü† L√≠mite de IA: aplicaci√≥n consistente y tracking visible

**Problema:** El bypass en `multi_processor.py` deja pasar correos de usuarios con AI limit = 0 hacia `single_processor`, que puede consumir cuota silenciosamente.

**Fix backend:**
```python
# multi_processor.py ‚Äî verificar que el check es estricto:
if user.ai_invoices_processed >= user.ai_invoices_limit and not has_xml_candidates:
    raise AILimitReachedError(f"Usuario {user_email} alcanz√≥ l√≠mite IA")
    # No pasar al single_processor si no hay candidatos XML
```

**Fix frontend:** En el Dashboard y en `/cuenta/suscripcion`, mostrar prominentemente:
- Barra de progreso: "X de Y facturas IA usadas"
- Alerta cuando llega al 80% y al 100%
- Bot√≥n "Upgrade" destacado cuando se agota el l√≠mite

---

### 2.5 üü† Suscripci√≥n de 15 d√≠as: verificar flujo completo con Google

**Problema declarado:** "Inicialmente cuando alguien se registra con Google se le da una suscripci√≥n de 15 d√≠as" ‚Äî verificar que esto realmente ocurre.

**Flujo esperado:**
1. Usuario hace login con Google ‚Üí Firebase Auth
2. Backend recibe JWT de Firebase ‚Üí verifica si es usuario nuevo
3. Si es nuevo ‚Üí crear documento en `auth_users` con `trial_start: now()`, `trial_days: 15`, `ai_invoices_limit: 50`
4. Crear registro en `user_subscriptions` con plan TRIAL activo
5. Frontend muestra el per√≠odo de prueba y sus l√≠mites en `/cuenta/suscripcion`

**Verificar:** Si el backend tiene un endpoint o middleware que detecta "primer login" y aplica el trial. Si no existe, est√° roto.

---

## FASE 3 ‚Äî Performance y Calidad del C√≥digo

### ‚úÖ 3.1 Locking distribuido para Kubernetes

**Problema:** `PROCESSING_LOCK` es un `threading.Lock` en memoria. Con m√∫ltiples pods en Kubernetes, dos pods pueden procesar el mismo correo simult√°neamente.

**Soluci√≥n:** Redis-based distributed lock:
```python
# backend/app/core/distributed_lock.py
import redis
from contextlib import contextmanager

@contextmanager
def distributed_lock(redis_client, key: str, timeout: int = 30):
    lock_key = f"lock:{key}"
    acquired = redis_client.set(lock_key, "1", nx=True, ex=timeout)
    try:
        if acquired:
            yield True
        else:
            yield False
    finally:
        if acquired:
            redis_client.delete(lock_key)
```

---

### 3.2 üü° Rate limiting en endpoints cr√≠ticos

**Problema:** No hay protecci√≥n contra abuso en endpoints de procesamiento y admin.

**Soluci√≥n:** Agregar `slowapi` (rate limiter para FastAPI):
```python
# app/api/api.py
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

# En endpoints:
@router.post("/process-direct")
@limiter.limit("10/minute")  # 10 solicitudes por minuto
async def process_direct(...):
```

---

### 3.3 üü° Frontend: OnPush + trackBy en componentes cr√≠ticos

**Componentes a actualizar:**
1. `queue-events.component.ts` ‚Äî `changeDetection: ChangeDetectionStrategy.OnPush` + `trackBy`
2. `invoices-v2.component.ts` ‚Äî `trackBy` en la lista de facturas
3. `admin-panel.component.ts` ‚Äî cachear datos entre tabs

```typescript
// Ejemplo para queue-events
@Component({
  changeDetection: ChangeDetectionStrategy.OnPush,
})
export class QueueEventsComponent {
  trackByJobId = (_: number, item: QueueEvent) => item.job_id;
}
```

---

### 3.4 üü° √çndices MongoDB faltantes

**Agregar √≠ndices para consultas frecuentes:**
```javascript
// invoice_headers
db.invoice_headers.createIndex({ owner_email: 1, created_at: -1 })
db.invoice_headers.createIndex({ owner_email: 1, processing_method: 1 })

// processed_emails
db.processed_emails.createIndex({ owner_email: 1, status: 1 })
db.processed_emails.createIndex({ message_id: 1 }, { unique: true })

// user_subscriptions
db.user_subscriptions.createIndex({ owner_email: 1, status: 1 })
db.user_subscriptions.createIndex({ next_billing_date: 1, status: 1 })  // Para cronjob de cobros
```

---

### 3.5 üü° Cleanup de c√≥digo legacy

**Items a limpiar:**
1. Exporters comentados en c√≥digo pero nunca eliminados
2. M√∫ltiples estrategias de fallback de processing duplicadas
3. Rutas de redireccionamiento legacy en Angular (10+ redirects a rutas antiguas)
4. Colecci√≥n `invoice_data` legacy vs `invoice_headers` v2 ‚Äî confirmar que solo se usa v2
5. Dependencias no usadas en `requirements.txt` (m√∫ltiples extractores PDF: pdfplumber, pdfminer, PyPDF2, PyMuPDF ‚Äî ¬øcu√°l se usa realmente?)

---

### 3.6 üü° Audit logging completo en operaciones admin

**Problema:** Cambios cr√≠ticos (suspender usuario, cambiar plan, reset AI limits) no tienen audit trail completo.

**Soluci√≥n:** Crear colecci√≥n `admin_audit_log`:
```python
# Estructura:
{
  "timestamp": datetime,
  "admin_email": str,
  "action": str,  # "suspend_user", "change_plan", "reset_ai_limit"
  "target_user": str,
  "details": dict,
  "ip_address": str
}
```

---

## FASE 4 ‚Äî Completar Funcionalidades Faltantes

### 4.1 üü° Upload manual: verificar todos los flujos

**El usuario declar√≥ que existe:** Subida manual de PDF, XML e im√°genes.

**Verificar que funcionan correctamente:**
- [ ] PDF upload ‚Üí OpenAI Vision ‚Üí invoice_headers
- [ ] XML upload ‚Üí Parser SIFEN nativo ‚Üí invoice_headers
- [ ] Imagen upload ‚Üí OpenAI Vision ‚Üí invoice_headers
- [ ] L√≠mite de IA se descuenta correctamente al subir
- [ ] Archivo se sube a MinIO despu√©s de procesar
- [ ] Error handling: ¬øqu√© pasa si la IA falla? ¬øse muestra el error?
- [ ] Plan check: ¬øusuarios trial pueden subir?

---

### 4.2 üü° Descarga desde MinIO condicionada por plan

**Problema declarado:** "de acuerdo al plan lo pueden descargar o no"

**Verificar implementaci√≥n:**
1. Endpoint `GET /invoices/{id}/download` ‚Üí ¬øverifica plan antes de generar URL firmada?
2. Frontend ‚Üí ¬ødeshabilita bot√≥n de descarga para planes sin acceso?
3. URL firmada ‚Üí ¬øtiene TTL apropiado (15-30 minutos)?

---

### 4.3 üü° P√°gina de Ayuda (/cuenta/ayuda)

**Estado actual:** M√≠nima o vac√≠a.

**Contenido propuesto:**
- Gu√≠a de inicio r√°pido (conectar primer correo, procesar primeras facturas, exportar)
- FAQ: ¬øPor qu√© no se procesan mis correos? ¬øQu√© es el l√≠mite de IA?
- Gu√≠a de configuraci√≥n de b√∫squeda (t√©rminos, sin√≥nimos, fallbacks)
- Videos embed de demo (si existen)
- Contacto de soporte

---

### 4.4 üü° Server-Sent Events (SSE) para cola en tiempo real

**Objetivo:** Reemplazar el polling de 5s en la cola de procesos con actualizaciones push del servidor.

**Backend ‚Äî agregar endpoint SSE:**
```python
from sse_starlette.sse import EventSourceResponse

@router.get("/queue/stream")
async def queue_stream(request: Request, current_user = Depends(get_current_user)):
    async def event_generator():
        while True:
            if await request.is_disconnected():
                break
            events = await get_recent_queue_events(current_user.email)
            yield {"data": json.dumps(events)}
            await asyncio.sleep(3)
    return EventSourceResponse(event_generator())
```

**Frontend ‚Äî usar `EventSource` en lugar de `interval()`:**
```typescript
// queue-events.component.ts
const source = new EventSource(`/api/queue/stream?token=${token}`);
source.onmessage = (event) => {
  this.events = JSON.parse(event.data);
  this.cdr.markForCheck();
};
```

---

## FASE 5 ‚Äî Infraestructura y Observabilidad

### 5.1 üü¢ Completar Prometheus metrics

**M√©tricas faltantes importantes:**
```python
# Agregar en app/utils/extended_metrics.py:
EMAILS_PROCESSED_TOTAL = Counter('emails_processed_total', 'Emails procesados', ['method', 'status'])
OPENAI_COST_GAUGE = Gauge('openai_estimated_cost_usd', 'Costo estimado OpenAI en USD')
QUEUE_DEPTH = Gauge('rq_queue_depth', 'Jobs en cola RQ', ['queue_name'])
AI_LIMIT_HITS = Counter('ai_limit_hits_total', 'Veces que se alcanz√≥ l√≠mite IA por usuario', ['user'])
```

---

### 5.2 üü¢ Backup y recuperaci√≥n de MongoDB

**Problema documentado:** No hay procedimientos de backup/restore documentados.

**Soluci√≥n m√≠nima:**
```bash
# Script de backup (agregar a scripts/backup-mongodb.sh):
#!/bin/bash
DATE=$(date +%Y%m%d_%H%M%S)
mongodump --uri="$MONGODB_URL" --out="/backups/mongodb_$DATE"
# Upload a MinIO u S3
```

**Configurar:** CronJob de Kubernetes o cron en servidor para backup diario.

---

### 5.3 üü¢ Documentar proceso de disaster recovery

- Qu√© hacer si MongoDB se corrompe
- C√≥mo restaurar desde backup de MinIO
- C√≥mo reiniciar el stack completo desde cero con datos existentes
- Runbook para incidentes de producci√≥n

---

## Tabla Resumen de Prioridades

| # | Problema | Impacto | Esfuerzo | Fase |
|---|----------|---------|---------|------|
| 1 | Cola de procesos pesta√±ea | Usuario bloqueado | Bajo | 1 |
| 2 | Admin email hardcodeado | Seguridad cr√≠tica | Bajo | 1 |
| 3 | Contrase√±as IMAP plaintext | Seguridad cr√≠tica | Medio | 1 |
| 4 | Tokens OAuth plaintext | Seguridad alta | Medio | 1 |
| 5 | print() en producci√≥n | Calidad c√≥digo | Bajo | 1 |
| 6 | Panel admin: datos reales + dise√±o | UX admin | Alto | 2 |
| 7 | Estad√≠sticas: calidad y origen | Visibilidad negocio | Medio | 2 |
| 8 | Verificar Pagopar completo | Facturaci√≥n/ingresos | Medio-Alto | 2 |
| 9 | L√≠mite IA: bypass y visibilidad | Integridad datos | Medio | 2 |
| 10 | Trial con Google: flujo completo | Onboarding | Medio | 2 |
| 11 | Locking distribuido (K8s) | Escalabilidad | Medio | 3 |
| 12 | Rate limiting en API | Seguridad | Bajo | 3 |
| 13 | OnPush + trackBy en frontend | Performance frontend | Bajo | 3 |
| 14 | √çndices MongoDB faltantes | Performance DB | Bajo | 3 |
| 15 | Cleanup c√≥digo legacy | Mantenibilidad | Medio | 3 |
| 16 | Audit log admin ops | Compliance | Medio | 3 |
| 17 | Upload manual: verificar flujos | Funcionalidad core | Bajo | 4 |
| 18 | Descarga MinIO por plan | Funcionalidad negocio | Bajo | 4 |
| 19 | P√°gina de Ayuda | UX onboarding | Bajo | 4 |
| 20 | SSE para cola en tiempo real | UX avanzado | Alto | 4 |
| 21 | M√©tricas Prometheus completas | Observabilidad | Bajo | 5 |
| 22 | Backup MongoDB automatizado | Resiliencia | Bajo | 5 |
| 23 | Documentar disaster recovery | Operaciones | Bajo | 5 |

---

## Preguntas Abiertas que Necesitan Respuesta

Estas preguntas surgieron del an√°lisis y requieren decisi√≥n antes de implementar:

1. **¬øEl panel de admin debe ser una ruta separada o un m√≥dulo dentro de la app principal?** Actualmente es `/admin` en la misma app Angular, lo cual expone el c√≥digo admin a todos los usuarios aunque est√© protegido por guard.

2. **¬øQu√© datos de "calidad" quiere ver el usuario en Estad√≠sticas?** El punto 11 menciona "estad√≠stica de calidad y origen" ‚Äî ¬øse refiere a XML vs IA, o hay m√©tricas adicionales como tiempo de procesamiento, correos duplicados detectados, etc.?

3. **¬øEl Explorador de Facturas (`/facturas/explorador`) est√° completo o falta funcionalidad espec√≠fica?** No est√° claro qu√© diferencia tiene del listado normal en `/facturas/todas`.

4. **¬øLa integraci√≥n de Pagopar est√° activa en producci√≥n actualmente?** Si s√≠, ¬øhay cobros reales en curso que puedan romperse con cambios?

5. **¬øHay planes de migrar de Angular 15 a una versi√≥n m√°s reciente (17+)?** Angular 15 est√° en fin de soporte. La migraci√≥n puede traer mejoras de performance pero requiere trabajo.

6. **¬øSe usa el campo `processing_method` en `invoice_headers` actualmente?** Si no se guarda en todos los paths, hay que retroalimentar los registros existentes.

7. **¬øCu√°ntos usuarios activos hay en producci√≥n?** Determina la urgencia de mejoras de performance y el impacto de cambios.

8. **¬øEl worker RQ corre como un √∫nico pod o m√∫ltiples en Kubernetes?** Si es m√∫ltiple, el locking distribuido es urgente (no medio).

---

## Convenci√≥n para este Plan

- Cuando se resuelva un item, agregar ‚úÖ al inicio de su secci√≥n
- Documentar cualquier decisi√≥n de dise√±o importante que cambie lo descrito aqu√≠
- Si se descubren nuevos problemas, agregarlos en la fase correcta
- Este plan se revisa y actualiza cada vez que se completa una fase
