Te comparto un ejemplo que no es monorepo, pero funciona 
Backend:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: legajo-backend
  namespace: legajo-backend
  labels:
    app: legajo-backend
    tier: backend
spec:
  replicas: 2  # âœ… mejor tener al menos 2 para HA
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0  # âœ… nunca dejar en 0 (alta disponibilidad)
  selector:
    matchLabels:
      app: legajo-backend
      tier: backend
  template:
    metadata:
      labels:
        app: legajo-backend
        tier: backend
    spec:
      containers:
      - name: legajo-backend
        image: ghcr.io/poravv/api-rest-legajo:latest   # âœ… etiqueta clara
        imagePullPolicy: Always
        ports:
        - containerPort: 3000
          name: http
        env:
        - name: PORT
          value: "3000"
        envFrom:
        - secretRef:
            name: backend-env-secrets
        - configMapRef:
            name: backend-config
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: http   # âœ… usar el nombre del puerto declarado
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: http   # âœ… igual, mÃ¡s claro que poner el nÃºmero
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh","-c","sleep 15"]
      imagePullSecrets:
      - name: ghcr-secret
---
apiVersion: v1
kind: Service
metadata:
  name: legajo-backend-service
  namespace: legajo-backend
  labels:
    app: legajo-backend
    tier: backend
spec:
  type: ClusterIP   # âœ… solo accesible dentro del cluster
  selector:
    app: legajo-backend
    tier: backend
  ports:
  - port: 3000       # puerto interno expuesto al frontend
    targetPort: http # referencia por nombre
    name: http
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: legajo-backend-hpa
  namespace: legajo-backend
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: legajo-backend
  minReplicas: 2   # âœ… mantener siempre 2 (tolerancia a fallos)
  maxReplicas: 10
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
      selectPolicy: Max
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      selectPolicy: Max
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80


apiVersion: v1
kind: ConfigMap
metadata:
  name: backend-config
  namespace: legajo-backend
data:
  # Database Configuration
  MYSQL_DB: "legajodb"
  MYSQL_HOST: "mysql-service"
  MYSQL_PORT: "3306"
  
  # Application Configuration
  APP_NAME: "Legajo Backend API"
  
  # Keycloak Configuration
  KEYCLOAK_URL: "https://kc.mindtechpy.net"
  KEYCLOAK_REALM: "LegajoUser"

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pvc
  namespace: legajo-backend
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi   # âœ… Arrancamos con 5Gi, escalable despuÃ©s
  storageClassName: longhorn
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
  namespace: legajo-backend
  labels:
    app: mysql
    tier: database
spec:
  replicas: 1
  strategy:
    type: Recreate   # âœ… Para que nunca haya dos pods con el mismo PVC
  selector:
    matchLabels:
      app: mysql
      tier: database
  template:
    metadata:
      labels:
        app: mysql
        tier: database
    spec:
      terminationGracePeriodSeconds: 60   # âœ… Da tiempo a MySQL de cerrar conexiones
      containers:
      - name: mysql
        image: mysql:8.0
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: legajo-backend-secrets
              key: mysql-root-password
        - name: MYSQL_DATABASE
          valueFrom:
            secretKeyRef:
              name: legajo-backend-secrets
              key: mysql-database
        - name: MYSQL_USER
          valueFrom:
            secretKeyRef:
              name: legajo-backend-secrets
              key: mysql-user
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: legajo-backend-secrets
              key: mysql-password
        - name: MYSQL_CHARSET
          value: "utf8mb4"
        - name: MYSQL_COLLATION
          value: "utf8mb4_unicode_ci"
        ports:
        - containerPort: 3306
          name: mysql
        volumeMounts:
        - name: mysql-storage
          mountPath: /var/lib/mysql
        resources:
          requests:
            memory: "1Gi"     # âœ… mÃ¡s realista para MySQL productivo
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:        # âœ… Simplificada para evitar reinicios falsos
          tcpSocket:
            port: 3306
          initialDelaySeconds: 60
          periodSeconds: 20
          failureThreshold: 5
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - mysqladmin ping -h 127.0.0.1 -uroot -p$MYSQL_ROOT_PASSWORD
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 10
      volumes:
      - name: mysql-storage
        persistentVolumeClaim:
          claimName: mysql-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: mysql-service
  namespace: legajo-backend
  labels:
    app: mysql
    tier: database
spec:
  type: ClusterIP   # âœ… Solo accesible desde dentro del cluster
  selector:
    app: mysql
    tier: database
  ports:
  - port: 3306
    targetPort: 3306
    name: mysql

apiVersion: v1
kind: Namespace
metadata:
  name: legajo-backend
  labels:
    name: legajo-backend



apiVersion: v1
kind: ConfigMap
metadata:
  name: frontend-config
  namespace: legajo-frontend
data:
  # URL que usarÃ¡ el frontend en el navegador (proxy inverso via ingress)
  BACKEND_API_URL: "/legajo/api"

  # URL interna dentro del cluster (frontend â†’ backend directo)
  INTERNAL_BACKEND_URL: "http://legajo-backend-service.legajo-backend.svc.cluster.local:3000"
  
  # ConfiguraciÃ³n de la aplicaciÃ³n
  APP_NAME: "Legajo Frontend"
  ENVIRONMENT: "production"
  
  # Keycloak (autenticaciÃ³n)
  KEYCLOAK_URL: "https://kc.mindtechpy.net"
  KEYCLOAK_REALM: "LegajoUser"

apiVersion: apps/v1
kind: Deployment
metadata:
  name: legajo-frontend
  namespace: legajo-frontend
  labels:
    app: legajo-frontend
    tier: frontend
spec:
  replicas: 2  # âœ… mÃ­nimo 2 para alta disponibilidad
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0   # âœ… nunca deje de haber un pod disponible
  selector:
    matchLabels:
      app: legajo-frontend
      tier: frontend
  template:
    metadata:
      labels:
        app: legajo-frontend
        tier: frontend
    spec:
      containers:
      - name: legajo-frontend
        image: ghcr.io/poravv/legajo-front:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 4000
          name: http
        envFrom:
        - configMapRef:
            name: frontend-config
        resources:
          requests:
            memory: "256Mi"   # âœ… mÃ¡s memoria para prevenir OOM en producciÃ³n
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health   # âš ï¸ asegÃºrate de que tu frontend expone esta ruta
            port: 4000
          initialDelaySeconds: 20
          periodSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: 4000
          initialDelaySeconds: 5
          periodSeconds: 5
          failureThreshold: 3
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh","-c","sleep 10"]
      imagePullSecrets:
      - name: ghcr-secret
---
apiVersion: v1
kind: Service
metadata:
  name: legajo-frontend-service
  namespace: legajo-frontend
  labels:
    app: legajo-frontend
    tier: frontend
spec:
  type: ClusterIP
  selector:
    app: legajo-frontend
    tier: frontend
  ports:
  - port: 4000
    targetPort: 4000
    name: http
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: legajo-frontend-hpa
  namespace: legajo-frontend
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: legajo-frontend
  minReplicas: 2   # âœ… igual que arriba: al menos 2 rÃ©plicas
  maxReplicas: 5
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
      selectPolicy: Max
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      selectPolicy: Max
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70


apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: legajo-frontend-ingress
  namespace: legajo-frontend
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    acme.cert-manager.io/http01-edit-in-place: "true"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - legajo.mindtechpy.net
      secretName: legajo-frontend-tls-secret
  rules:
    - host: legajo.mindtechpy.net
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: legajo-frontend-service
                port:
                  number: 4000


apiVersion: v1
kind: Namespace
metadata:
  name: legajo-frontend
  labels:
    name: legajo-frontend


Aqui el deploy name: Backend + Database CI/CD

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

# Permisos mÃ­nimos necesarios para este pipeline
permissions:
  contents: read
  packages: write

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}     # asegÃºrate de que el repo en GH sea lowercase (GHCR es case-sensitive)
  NAMESPACE: legajo-backend
  DOCKER_BUILDKIT: "1"

# Evita despliegues concurrentes sobre la misma rama
concurrency:
  group: deploy-${{ github.ref }}
  cancel-in-progress: false

jobs:
  test:
    runs-on: self-hosted
    name: Test Backend
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
        env:
          npm_config_cache: ${{ github.workspace }}/.npm

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Run linting
        run: |
          if grep -q "\"lint\":" package.json; then
            npm run lint || echo "Lint warnings ignored"
          else
            echo "No lint script found, skipping..."
          fi

      - name: Run tests
        run: |
          if grep -q "\"test\":" package.json; then
            npm test || echo "Tests completed"
          else
            echo "No test script found, skipping..."
          fi

  build-and-deploy:
    needs: test
    runs-on: self-hosted
    name: Build and Deploy Backend + Database
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          install: true

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_PAT }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=sha,format=short
            type=raw,value=latest
          labels: |
            org.opencontainers.image.source=${{ github.repository }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

      # --- Kubernetes deploy ---
      - name: Ensure namespace exists
        run: |
          kubectl get ns ${{ env.NAMESPACE }} || kubectl create ns ${{ env.NAMESPACE }}

      - name: Create/Update image pull secret (GHCR)
        run: |
          kubectl create secret docker-registry ghcr-secret \
            --docker-server=${{ env.REGISTRY }} \
            --docker-username=${{ github.actor }} \
            --docker-password=${{ secrets.GHCR_PAT }} \
            --namespace=${{ env.NAMESPACE }} \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Create/Update application secrets
        run: |
          set -euo pipefail
          kubectl delete secret backend-env-secrets -n ${{ env.NAMESPACE }} --ignore-not-found=true
          kubectl create secret generic backend-env-secrets \
            --namespace=${{ env.NAMESPACE }} \
            --from-literal=DB_HOST="${{ secrets.DB_HOST }}" \
            --from-literal=DB_PORT="${{ secrets.DB_PORT }}" \
            --from-literal=DB_USER="${{ secrets.DB_USER }}" \
            --from-literal=DB_PASSWORD="${{ secrets.DB_PASSWORD }}" \
            --from-literal=DB_DATABASE="${{ secrets.DB_DATABASE }}" \
            --from-literal=NODE_ENV="production" \
            --from-literal=PORT="3000" \
            --from-literal=CLAVESECRETA="${{ secrets.CLAVESECRETA }}" \
            --from-literal=REALM_PUBLICK_KEY="${{ secrets.REALM_PUBLICK_KEY }}" \
            --from-literal=API_URL="${{ secrets.API_URL }}" \
            --from-literal=REDIS_URL="${{ secrets.REDIS_URL }}" \
            --from-literal=REDIS_PASSWORD="${{ secrets.REDIS_PASSWORD }}"

      - name: Create/Update MySQL secrets
        run: |
          set -euo pipefail
          kubectl delete secret legajo-backend-secrets -n ${{ env.NAMESPACE }} --ignore-not-found=true
          kubectl create secret generic legajo-backend-secrets \
            --namespace=${{ env.NAMESPACE }} \
            --from-literal=mysql-root-password="${{ secrets.MYSQL_ROOT_PASSWORD }}" \
            --from-literal=mysql-user="${{ secrets.MYSQL_USER }}" \
            --from-literal=mysql-password="${{ secrets.MYSQL_PASSWORD }}" \
            --from-literal=mysql-database="${{ secrets.MYSQL_DATABASE }}"

      - name: Apply configmap
        run: |
          kubectl apply -f k8s/configmap.yaml -n ${{ env.NAMESPACE }}

      - name: Deploy database
        run: |
          set -euo pipefail
          echo "ğŸ’¾ Applying MySQL (Deployment + PVC + Service)..."
          kubectl apply -f k8s/mysql-deployment.yaml -n ${{ env.NAMESPACE }}
          echo "â³ Waiting rollout for MySQL deployment..."
          kubectl rollout status deployment/mysql -n ${{ env.NAMESPACE }} --timeout=600s
          echo "â³ Waiting pod readiness (label app=mysql)..."
          kubectl wait --for=condition=ready pod -l app=mysql -n ${{ env.NAMESPACE }} --timeout=600s

      - name: Test database connection
        run: |
          set -euo pipefail
          echo "ğŸ” Testing database connection..."
          MYSQL_POD=$(kubectl get pods -n ${{ env.NAMESPACE }} -l app=mysql -o jsonpath='{.items[0].metadata.name}')
          kubectl exec -n ${{ env.NAMESPACE }} "$MYSQL_POD" -- sh -c 'mysqladmin ping -h 127.0.0.1 -uroot -p"$MYSQL_ROOT_PASSWORD"'

      - name: Get short SHA
        run: echo "SHORT_SHA=$(echo $GITHUB_SHA | cut -c1-7)" >> $GITHUB_ENV

      - name: Deploy backend
        run: |
          set -euo pipefail
          echo "ğŸ”§ Applying backend manifests..."
          kubectl apply -f k8s/backend-deployment.yaml -n ${{ env.NAMESPACE }}
          echo "ğŸ“Œ Pin image to current commit..."
          kubectl set image deployment/legajo-backend \
            legajo-backend=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:sha-${SHORT_SHA} \
            -n ${{ env.NAMESPACE }}
          kubectl rollout status deployment/legajo-backend -n ${{ env.NAMESPACE }} --timeout=300s

      - name: Backend health check (ClusterIP)
        run: |
          set -euo pipefail
          echo "ğŸ¥ Checking backend health..."
          BACKEND_IP=$(kubectl get svc legajo-backend-service -n ${{ env.NAMESPACE }} -o jsonpath='{.spec.clusterIP}')
          for i in $(seq 1 12); do
            if curl -fsS "http://${BACKEND_IP}:3000/health" > /dev/null; then
              echo "âœ… Backend healthy"
              exit 0
            fi
            echo "Attempt $i/12 failed; retrying in 10s..."
            sleep 10
          done
          echo "âŒ Backend health check failed"
          exit 1

      - name: Dump diagnostics on failure
        if: failure()
        run: |
          echo "ğŸ” Dumping diagnostics..."
          kubectl get pods -n ${{ env.NAMESPACE }} -o wide
          kubectl describe deploy/mysql -n ${{ env.NAMESPACE }} || true
          kubectl describe deploy/legajo-backend -n ${{ env.NAMESPACE }} || true
          MYSQL_POD=$(kubectl get pods -n ${{ env.NAMESPACE }} -l app=mysql -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
          if [ -n "$MYSQL_POD" ]; then
            echo "ğŸ“œ MySQL last logs:"; kubectl logs "$MYSQL_POD" -n ${{ env.NAMESPACE }} --tail=100 || true
          fi
          APP_POD=$(kubectl get pods -n ${{ env.NAMESPACE }} -l app=legajo-backend -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
          if [ -n "$APP_POD" ]; then
            echo "ğŸ“œ Backend last logs:"; kubectl logs "$APP_POD" -n ${{ env.NAMESPACE }} --tail=200 || true
          fi

      - name: Deployment summary
        if: always()
        run: |
          echo "ğŸ“‹ Deployment Summary:"
          echo "===================="
          echo "Job status: ${{ job.status }}"
          echo ""
          echo "ğŸ“Š Pods:"
          kubectl get pods -n ${{ env.NAMESPACE }}
          echo ""
          echo "ğŸ”— Services:"
          kubectl get svc -n ${{ env.NAMESPACE }}
          echo ""
          echo "â„¹ï¸ Backend remains internal-only (no public Ingress)."